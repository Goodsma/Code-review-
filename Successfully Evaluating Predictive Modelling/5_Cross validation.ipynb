{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38902a6-a5aa-4b85-8cab-9ee379f130a9",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c22b5-69f5-4851-b53e-552064225803",
   "metadata": {},
   "source": [
    "## The dataset and classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772451e-d92b-44d9-95f5-e28b0ffb50ae",
   "metadata": {},
   "source": [
    "First, let's introduce the dataset and divide it into training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fafa3000-ac71-45af-a654-74dc4b16e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights = (0.7,0.3), class_sep=0.99, random_state=14)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1745630-e07a-4b5d-8251-337c298c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f60264-ba06-46cf-9c22-e57b8423dc24",
   "metadata": {},
   "source": [
    "## Applying cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d10edb7-d966-472f-82f8-d7af15734686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores: [0.97857143 1.         0.97857143 0.99285714 0.99285714]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "print('Accuracy scores: '+str(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75211ae7-39ac-484e-a9b8-f20fbea63dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.99431818 1.         1.         0.99147727 1.\n",
      " 1.         1.         0.9718173  1.        ]\n"
     ]
    }
   ],
   "source": [
    "outcomes = cross_val_score(classifier, X_train, y_train, cv=10, scoring = 'roc_auc')\n",
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c71e07d-c3ae-4b5f-a9e2-d346e5396c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00500107 0.00300336 0.00301099 0.00400186 0.00500321 0.00502777\n",
      " 0.00300097 0.00299907 0.0039947  0.00399709]\n",
      "score_time value: [0.01000071 0.00699234 0.00799656 0.00599599 0.01402617 0.00495982\n",
      " 0.00699401 0.00599527 0.00499988 0.00500202]\n",
      "test_roc_auc value: [1.         0.99431818 1.         1.         0.99147727 1.\n",
      " 1.         1.         0.9718173  1.        ]\n",
      "train_roc_auc value: [0.99679871 0.99722555 0.99684614 0.99691728 0.9973204  0.9969616\n",
      " 0.99691431 0.99671333 0.99949163 0.99673697]\n",
      "test_accuracy value: [0.95714286 0.98571429 1.         1.         0.97142857 1.\n",
      " 1.         0.98571429 0.98571429 1.        ]\n",
      "train_accuracy value: [0.99206349 0.99206349 0.98888889 0.98888889 0.99365079 0.98888889\n",
      " 0.98888889 0.99047619 0.99047619 0.98888889]\n",
      "test_precision value: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "train_precision value: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "metrics = ['roc_auc','accuracy','precision']\n",
    "\n",
    "# By default, we should not really care about the training scores. To show them, we add the extra return_train_score parameter\n",
    "outcomes = cross_validate(classifier, X_train, y_train,scoring=metrics, cv=10, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+' value: '+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1871e3-ee40-4264-b64b-c45dbdc1495c",
   "metadata": {},
   "source": [
    "Now, the outcome is a dictionary with the different metrics per fold for both the training and test set (note that, since we have set aside a separate test set, this is our validation set in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1fc627-f323-4235-baac-73001cab5380",
   "metadata": {},
   "source": [
    "## Setting up a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1922d0-0d97-43e2-878d-4290f3898f6a",
   "metadata": {},
   "source": [
    "Remember when we talked about training, validation and test sets, we mentioned that the pre-processing (e.g., replacing missing values, transformations, over- and under-sampling, etc.) should be performed on the training and test set separately to avoid any bias? That is, the same transformation, with the same parameters, should be applied to both. Otherwise, information of the training set can 'leak' into the testing process, while the testing stage needs to be completely independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549520b-4ed8-4825-a40b-a2ce7845ae6b",
   "metadata": {},
   "source": [
    "To simplify this, we can set up a pipeline containing the various steps that need to be applied, i.e., transformation and training a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "415ed322-fbd4-4ac2-b236-c4f56c15aae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00399804 0.00199819 0.0039947  0.00300407 0.00399184 0.00199652\n",
      " 0.00299931 0.00299907 0.00199938 0.00300384]\n",
      "score_time value: [0.         0.00099897 0.0010035  0.00100303 0.         0.00100064\n",
      " 0.         0.0009973  0.00100541 0.00099778]\n",
      "test_accuracy value: [0.97142857 0.98571429 1.         1.         0.97142857 0.98571429\n",
      " 1.         0.98571429 0.98571429 1.        ]\n",
      "train_accuracy value: [0.99206349 0.99206349 0.99047619 0.99047619 0.99206349 0.99047619\n",
      " 0.98888889 0.99047619 0.99047619 0.98888889]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "metrics = ['accuracy']\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), classifier)\n",
    "outcomes = cross_validate(pipeline, X_train, y_train, scoring=metrics, cv=10, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+' value: '+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9172f4-b22d-4871-b648-a53cced91c37",
   "metadata": {},
   "source": [
    "## Predictions for every sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35985605-0883-469b-ab83-c62ea1727a0b",
   "metadata": {},
   "source": [
    "If you want to obtain the predictions for every sample from when it was in the test set (in 10-fold CV, every sample is used exactly once), the following code can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bbc39a5-07e7-4def-a9d2-bd50eb3b86f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = cross_val_predict(pipeline, X_train, y_train, cv=10)\n",
    "print(accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74f9e05-9710-48b3-84f8-34dd1dcce887",
   "metadata": {},
   "source": [
    "Typically, we will use cross-validation to see what classifier, or what parameters, are working best over our training/validation sets. Then, finally, we use them on our test set for our final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e996ed6-a376-43d3-826f-eccd4e084a19",
   "metadata": {},
   "source": [
    "## Adding sampling strategy to pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81814cb1-a9cc-4a41-a1bb-c542975a4526",
   "metadata": {},
   "source": [
    "Since our data is imbalanced, we might want to preserve this imbalance in every fold. To do so, we can use the stratified CV procedure as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5606c0c-ec8e-41fa-87be-16398c36465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00499368 0.00399804 0.00300169 0.00399947 0.00400329 0.00299883\n",
      " 0.00399995 0.00401187 0.00299835 0.00399733]\n",
      "score_time value: [0.00099826 0.00100183 0.00100493 0.00100017 0.00302482 0.00099945\n",
      " 0.         0.00098896 0.00100327 0.        ]\n",
      "test_accuracy value: [0.98571429 0.98571429 1.         1.         1.         0.98571429\n",
      " 0.97142857 0.98571429 0.98571429 1.        ]\n",
      "train_accuracy value: [0.99206349 0.99206349 0.98888889 0.98888889 0.98888889 0.99206349\n",
      " 0.99206349 0.99206349 0.99047619 0.99047619]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, random_state=40, shuffle=True)\n",
    "outcomes = cross_validate(pipeline, X_train, y_train, scoring=metrics, cv=stratified_kfold, return_train_score=True)\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+' value: '+str(outcomes[metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997c1c5-0b5f-428b-8708-22321432ef3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
